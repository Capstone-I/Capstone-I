{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This section is for workflow configuration.\n",
    "This includes:\n",
    "- Setting the name of this model\n",
    "- Choosing to skip certain parts\n",
    "- Choosing whether to reload a past model or not\n",
    "- Choosing which parts to save or not save\n",
    "- Choosing a seed for algorithms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1719b365348e4de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit.utils import algorithm_globals\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "base_model_name = \"covertype-effdim-01\"\t# Name to be used for saving and loading models. Filename friendly string\n",
    "\t\t\t\t\t\t\t\t\t\t# NOTE: Filename is not sanitized. Edit at your own risk.\n",
    "dataset_name = \"cover-type\"\t\t\t\t# Name of the dataset. Used for the log file. String\n",
    "\n",
    "skip_effective_dimension = False\t\t# If true, skip the effective dimension graphs for quantum and dynamic circuits\n",
    "\t\t\t\t\t\t\t\t\t\t# Can save time if you are simply interested in collecting accuracy data.\n",
    "\n",
    "skip_classical = False\t\t\t\t\t# If true, skip the entire classical model parts.\n",
    "skip_quantum = False\t\t\t\t\t# If true, skip the entire quantum model parts.\n",
    "skip_dynamic = False\n",
    "\n",
    "reload_classical = False\t\t\t\t# If true, reload classical model from <base>-classical.keras.\n",
    "reload_quantum = False\t\t\t\t\t# If true, reload quantum model from <base>-quantum.model.\n",
    "reload_dynamic = False\n",
    "\n",
    "save_classical_model = False\t\t\t# If true, save classical model to <base>-classical.keras.\n",
    "save_quantum_model = False\t\t\t\t# If true, save quantum model to <base>-quantum.model.\n",
    "save_dynamic_model = False\n",
    "\n",
    "save_comparison_to_file = True\t\t\t# If true, save accuracy and runtime stats to <base>-comparison.log.\n",
    "overwrite_old_log = True\t\t\t\t# If true and a log exists where this one would be saved, overwrite it\n",
    "skip_header = False\t\t\t\t\t\t# When true, skip the header\n",
    "\n",
    "play_sound = True\t\t\t\t\t\t# If true, play a sound when the notebook is finished.\n",
    "sound_filename = \"vine-boom.mp3\"\t\t# Filename of sound to play. Must be located in ./assets\n",
    "\t\t\t\t\t\t\t\t\t\t# NOTE: Filename is not sanitized. Edit at your own risk.\n",
    "\n",
    "seed = random.randint(0,99999)\t\t\t# Seed for randomization. Integer\n",
    "algorithm_globals.random_seed = seed\n",
    "print(seed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2264a269b6ff50d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This section is for model configuration.\n",
    "This includes:\n",
    "- Number of iterations for training\n",
    "- Data sampling settings\n",
    "  - Whether to use a fraction or a set number for the data sample count.\n",
    "  - Fraction of data subset to sample.\n",
    "  - Number of data entries to sample \n",
    "- Fraction of data to use for training (rest is for testing)\n",
    "- Maximum size of data batches to be fed into the models.\n",
    "- Number of features for PCA reduction (used due to memory/qubit constraints.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d86064015dff6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iterations = 80\t\t\t# The set iteration limit for the optimizer. Integer > 0\n",
    "use_frac = False\t\t# If true, use data_frac as a fraction for sample size. Else use data_count.\n",
    "data_frac = 0.005\t\t# Fraction of dataset to sample. Decimal [0-1]\n",
    "data_count = 1000\t\t\t# Number of data entries to sample. Integer [0-number of entries]\n",
    "train_frac = 0.8\t\t# Fraction of data subset from above to use on training. Decimal [0-1]\n",
    "batch_size = 250\t\t\t# Maximum batch size for models. Integer > 0\n",
    "num_features = 8\t\t# Number of features for model. RFV requires a 2^k number. Integer [0-features]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61acf6c945ec99d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This section is for Classical Neural Network specific configuration\n",
    "This includes:\n",
    "- Which optimizer to use\n",
    "- Which loss function to use\n",
    "- How many neurons the classical neural network uses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d43e4557fba53f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classical_optimizer = \"adam\"\n",
    "classical_loss = \"mae\"\n",
    "classical_inner_neuron_count = num_features*4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfe7716aa2ac48a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This section is for Quantum Neural Network specific configuration\n",
    "This includes:\n",
    "- Which sampler primitive to use\n",
    "- Which optimizer to use\n",
    "- QNN optimization and resilience levels\n",
    "- QNN shots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c89f71c802dbe052"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import qiskit.algorithms.optimizers\n",
    "from qiskit.circuit.library import EfficientSU2, ZZFeatureMap, ZFeatureMap\n",
    "from qiskit_machine_learning.utils.loss_functions import L2Loss, L1Loss, CrossEntropyLoss\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "sampler_choice = 1\t\t# Flag for which sampler to use. 0 = Default Sampler, 1 = Aer Sampler, 2 = IBM Sampler\n",
    "use_simulator = True\t# If true, IBM Sampler will use a simulator. Otherwise, it will use a real machine.\n",
    "\n",
    "quantum_optimizer = qiskit.algorithms.optimizers.COBYLA(maxiter=iterations)\n",
    "\t\t\t\t\t\t# The optimizer object to use for optimizing the model.\n",
    "feature_map = ZFeatureMap(\n",
    "\tnum_features, \n",
    "\treps=1)\n",
    "ansatz = EfficientSU2(\n",
    "\tnum_qubits=feature_map.num_qubits, \n",
    "\treps=3, \n",
    "\tflatten=True)\t\t\t\n",
    "quantum_loss = L2Loss()\n",
    "\n",
    "opt_level = 1\t\t\t# The level of optimization for the circuits. [0, 1, 2, 3]\n",
    "res_level = 1\t\t\t# The level of resilience hardening for the circuits. [0, 1, 2, 3]\n",
    "shots = 1024\t\t\t# Number of repeated circuit executions for QNN. Integer > 0."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23eaff7fe9605aca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Effective Dimensions settings\n",
    "These settings are used for all effective dimension measurements, both in quantum and dynamic circuits."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5c088e34feafc79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_eff_dim_tests = 100\t\t\t\t# Number of categories to use for ED data collection (think number of trials)\n",
    "num_eff_dim_data = 25000\t\t\t# Maximum number of simulated data entries. The ED simulates incrementally larger 'datasets'\n",
    "num_eff_dim_weight_samples = 10\t\t# Number of random weight arrays to choose from.\n",
    "num_eff_dim_input_samples = 10\t\t# Number of random input arrays to choose from.\n",
    "ed_increment = int(num_eff_dim_data/num_eff_dim_tests)\n",
    "\t\t\t\t\t\t\t\t\t# The increment for the dataset sizes. By default, it is the amount needed to \n",
    "\t\t\t\t\t\t\t\t\t# fit num_eff_dim_tests data sizes.\n",
    "data_size_tests = [n for n in range(ed_increment, num_eff_dim_data+1, ed_increment)]\n",
    "\t\t\t\t\t\t\t\t\t# An array of dataset sizes to be given to the effective dimension.\n",
    "\t\t\t\t\t\t\t\t\t# The values refer to how much data is simulated for the measurement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a8cd23a1b0e7070"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This sections is for Dynamic QNN specific configuration\n",
    "This includes\n",
    "- Which optimizer to use\n",
    "- A description of the dynamic part of the algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2133b5ce74a27d11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dynamic_quantum_optimizer = qiskit.algorithms.optimizers.COBYLA(maxiter=iterations)\n",
    "dynamic_desc = \"Single Dynamic Rotation End Row with No Hadamards\"\n",
    "\n",
    "dynamic_feature_map = ZFeatureMap(\n",
    "\tnum_features, \n",
    "\treps=1)\n",
    "dynamic_ansatz = EfficientSU2(\n",
    "\tnum_qubits=dynamic_feature_map.num_qubits, \n",
    "\treps=3, \n",
    "\tskip_final_rotation_layer=True, \n",
    "\tflatten=True)\n",
    "dynamic_loss = L2Loss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cc06acf76407e7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation\n",
    "Here we prepare the dataset we want for use in the models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a091deea6b3f18a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import fetch_covtype\n",
    "import pandas as pd\n",
    "from os.path import normpath\n",
    "\n",
    "# Put data samples into features and labels from file\n",
    "data = fetch_covtype(data_home=\"./data\", as_frame=True)\n",
    "display(data.target)\n",
    "num_targets = len(data.target.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd937de05e04cf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_frac:\n",
    "\tfeatures = data.data.sample(frac=data_frac, random_state=seed)\n",
    "\tlabels = data.target.sample(frac=data_frac, random_state=seed).values\n",
    "else: \n",
    "\tfeatures = data.data.sample(n=data_count, random_state=seed)\n",
    "\tlabels = data.target.sample(n=data_count, random_state=seed).values\n",
    "features = features.values\n",
    "display(num_targets)\n",
    "display(features)\n",
    "display(labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77870e0313802aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA the features, and preprocess them.\n",
    "features = PCA(n_components=num_features).fit_transform(features)\n",
    "features = StandardScaler().fit_transform(features)\n",
    "labels = OrdinalEncoder().fit_transform(labels.reshape(-1,1))\n",
    "labels = labels[:,0]\n",
    "display(features, labels)\n",
    "display(features.shape, labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267740847a4ac845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate into training and testing sets.\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "\tfeatures,\n",
    "\tlabels,\n",
    "\ttrain_size=train_frac\n",
    ")\n",
    "display(train_features.shape, train_labels.shape, test_features.shape, test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcfb4f96b617cd21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import gen_batches\n",
    "\n",
    "# Create the slices that we can use for batches in training\n",
    "train_slices = list(gen_batches(train_features.shape[0], batch_size))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cbf21cbe8db906"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Data logging\n",
    "if save_comparison_to_file and not skip_header:\n",
    "\tif overwrite_old_log and os.path.isfile(f\"./logs/{base_model_name}.log\"):\n",
    "\t\tos.remove(f\"./logs/{base_model_name}.log\")\n",
    "\twith open(f\"./logs/{base_model_name}.log\", \"a+\") as file:\n",
    "\t\tfile.write(f\"Model Name:\\t{base_model_name}\\n\")\n",
    "\t\tfile.write(f\"Dataset:\\t{dataset_name}\\n\")\n",
    "\t\tfile.write(f\"Trial start:\\t{datetime.now()}\\n\")\n",
    "\t\tfile.write(f\"Number of features:\\t{num_features}\\n\")\n",
    "\t\tfile.write(f\"Number of data entries:\\t{features.shape[0]}\\n\")\n",
    "\t\tfile.write(f\"Batch size:\\t{batch_size}\\n\")\n",
    "\t\tfile.write(f\"Iterations:\\t{iterations}\\n\")\n",
    "\t\tfile.write(f\"Training fraction:\\t{train_frac}\\n\")\n",
    "\t\tfile.write(f\"Randomization seed:\\t{seed}\\n\")\n",
    "\t\tfile.write(\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f65a288ae7c0080"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classical Neural Network\n",
    "We now construct and run the classical neural network locally. This normally doesn't take long at all."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfad1280708c8cec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create the Keras neural network model\n",
    "if not skip_classical:\n",
    "\tif not reload_classical:\n",
    "\t\tclassical_model = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.Dense(classical_inner_neuron_count, \n",
    "\t\t\t\t\t\t\t\t  activation=\"relu\", \n",
    "\t\t\t\t\t\t\t\t  input_shape=[num_features]),\n",
    "\t\t\ttf.keras.layers.Dense(units=1)\n",
    "\t\t])\n",
    "\telse: \n",
    "\t\tclassical_model = tf.keras.models.load_model(f\"./models/{base_model_name}-classical.keras\")\n",
    "\tclassical_model.compile(optimizer=classical_optimizer,\n",
    "\t\t\t\t\t\t\tloss=classical_loss,\n",
    "\t\t\t\t\t\t\tmetrics=[\"accuracy\", \"sparse_categorical_accuracy\"]\n",
    "\t)\n",
    "\tclassical_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67bd49c78c14539d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model and use it\n",
    "if not skip_classical:\n",
    "\tstart = datetime.now()\n",
    "\tclassical_model.fit(x=train_features, y=train_labels, batch_size=batch_size, epochs=iterations)\n",
    "\tfinish = datetime.now()\n",
    "\tprint(f\"Model trained at {str(finish)}, for a total time of {str(finish-start)}\")\n",
    "\tif save_classical_model:\n",
    "\t\tclassical_model.save(f\"./models/{base_model_name}-classical.keras\")\n",
    "\tdisplay(classical_model.metrics_names)\n",
    "\tclassical_test_result = classical_model.evaluate(x=test_features, y=test_labels)\n",
    "\tclassical_train_result = classical_model.evaluate(x=train_features, y=train_labels)\n",
    "\tdisplay(f\"Classical Training results: {classical_train_result}\")\n",
    "\tdisplay(f\"Classical Testing results: {classical_test_result}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c32b10abd93cc26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "\n",
    "if not skip_classical and save_comparison_to_file:\n",
    "\twith open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "\t\tfile.write(f\"Classical Optimizer:\\t{classical_optimizer}\\n\")\n",
    "\t\tfile.write(f\"Classical Loss:\\t{classical_loss}\\n\")\n",
    "\t\tfile.write(f\"Classical Inner Neuron Count:\\t{classical_inner_neuron_count}\\n\")\n",
    "\t\tfile.write(f\"Classical Train Time:\\t{str(finish-start)}\\n\")\n",
    "\t\tfile.write(f\"Classical Testing Accuracy:\\t{classical_test_result[1]}\\n\")\n",
    "\t\tfile.write(f\"Classical Testing Sparse Categorical Accuracy:\\t{classical_test_result[2]}\\n\")\n",
    "\t\tfile.write(f\"Classical Training Accuracy:\\t{classical_train_result[1]}\\n\")\n",
    "\t\tfile.write(f\"Classical Training Sparse Categorical Accuracy:\\t{classical_train_result[2]}\\n\")\n",
    "\t\tfile.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2425b410d57d3c48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum Neural Network\n",
    "We construct a quantum neural network that can be ran locally or on an IBM simulator/quantum computer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39b29b45330154bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "\n",
    "# Construct the circuit\n",
    "if not skip_quantum:\n",
    "\t#feature_map = RawFeatureVector(num_features) # Note: RFV requires num_features = 2^k. Also known to break.\n",
    "\t\n",
    "\tcircuit = QuantumCircuit(feature_map.num_qubits)\n",
    "\tcircuit.compose(feature_map, inplace=True)\n",
    "\tcircuit.compose(ansatz, inplace=True)\n",
    "\t\n",
    "\t#ansatz.decompose().draw(output=\"mpl\")\n",
    "\tdisplay(circuit.draw(output=\"mpl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7df4eab2fb4ca6a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the interpreting function for the model\n",
    "if not skip_quantum:\n",
    "\tdef interpret(x):\n",
    "\t\treturn x%num_targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b566f5cb25d86d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Options\n",
    "import qiskit.primitives\n",
    "import qiskit_aer.primitives\n",
    "import qiskit_ibm_runtime.sampler\n",
    "from qiskit_ibm_runtime import Session\n",
    "\n",
    "# Configuring the Sampler primitive object\n",
    "if not skip_quantum:\n",
    "\tif sampler_choice == 1:\n",
    "\t\tcustom_sampler = qiskit_aer.primitives.Sampler()\n",
    "\t\tprint(\"Aer sampler\")\n",
    "\telif sampler_choice == 2:\n",
    "\t\tservice = QiskitRuntimeService(\n",
    "\t\t\tchannel='ibm_quantum',\n",
    "\t\t\tinstance='ibm-q-asu/main/pi-deluca'\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\toptions = Options()\n",
    "\t\toptions.execution.shots = shots\n",
    "\t\toptions.optimization_level = opt_level\n",
    "\t\toptions.resilience_level = res_level\n",
    "\t\t#options.transpilation.skip_transpilation = True\n",
    "\t\t\n",
    "\t\tif use_simulator:\n",
    "\t\t\tbackend = service.get_backend(\"simulator_statevector\")\n",
    "\t\telse:\n",
    "\t\t\tbackend = service.least_busy(min_num_qubits=feature_map.num_qubits, filters=lambda b: (b.configuration().simulator == True) and (b.configuration().conditional == True))\n",
    "\t\t\n",
    "\t\tprint(backend.name)\n",
    "\t\tsession = Session(backend=backend, service=service)\n",
    "\t\tcustom_sampler = qiskit_ibm_runtime.Sampler(session=session, options=options)\n",
    "\telse:\n",
    "\t\tcustom_sampler = qiskit.primitives.Sampler()\n",
    "\t\tprint(\"Default sampler\")\n",
    "\t\n",
    "\tsampler = SamplerQNN(sampler=custom_sampler,\n",
    "\t\t\t\t\t\t circuit=circuit,\n",
    "\t\t\t\t\t\t input_params=feature_map.parameters,\n",
    "\t\t\t\t\t\t weight_params=ansatz.parameters,\n",
    "\t\t\t\t\t\t interpret=interpret,\n",
    "\t\t\t\t\t\t output_shape=num_targets\n",
    "\t)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34234c3727d54bbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define the graph callback function\n",
    "if not skip_quantum:\n",
    "\tobjective_func_vals = []\n",
    "\tplt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\tplt.clf()\n",
    "\tdef callback_graph(weights, obj_func_eval):\n",
    "\t\tclear_output(wait=True)\n",
    "\t\tobjective_func_vals.append(obj_func_eval)\n",
    "\t\tplt.title(\"Objective function value against iteration\")\n",
    "\t\tplt.xlabel(\"Iteration\")\n",
    "\t\tplt.ylabel(\"Objective function value\")\n",
    "\t\tplt.plot(range(len(objective_func_vals)), objective_func_vals, color=(0.8,0.5,0.8))\n",
    "\t\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d26b95f68f80e360"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
    "\n",
    "# Create classifier\n",
    "if not skip_quantum:\n",
    "\tif not reload_quantum:\n",
    "\t\tclassifier = NeuralNetworkClassifier(\n",
    "\t\tsampler,\n",
    "\t\tone_hot=True,\n",
    "\t\toptimizer=quantum_optimizer,\n",
    "\t\tcallback=callback_graph,\n",
    "\t\twarm_start=True,\n",
    "\t\tloss=quantum_loss,\n",
    "\t\tinitial_point=algorithm_globals.random.random(sampler.num_weights)\n",
    "\t)\n",
    "\telse:\n",
    "\t\tclassifier = NeuralNetworkClassifier.load(f\"./models/{base_model_name}-quantum.model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9b927d993945cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import EffectiveDimension\n",
    "import numpy as np\n",
    "\n",
    "# Global Effective Dimension Measure\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "\tquantum_global_ed = EffectiveDimension(qnn=sampler, weight_samples=num_eff_dim_weight_samples, input_samples=num_eff_dim_input_samples)\n",
    "\tquantum_global_ed_measurement = np.array(quantum_global_ed.get_effective_dimension(dataset_size=data_size_tests))/sampler.num_weights\n",
    "\tplt.plot(data_size_tests, quantum_global_ed_measurement, color=(0.8,0.5,0.8))\n",
    "\tplt.xlabel(\"Number of data\")\n",
    "\tplt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a9e05e71e926abe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import LocalEffectiveDimension\n",
    "\n",
    "# Untrained Local Effective Dimension\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "\tquantum_local_ed_untrained = LocalEffectiveDimension(qnn=sampler, weight_samples=classifier.initial_point, input_samples=train_features)\n",
    "\tquantum_local_ed_untrained_measurement = np.array(quantum_local_ed_untrained.get_effective_dimension(dataset_size=data_size_tests))/sampler.num_weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315c38622209d73c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "if not skip_quantum:\n",
    "\tplt.clf()\n",
    "\tstart = datetime.now()\n",
    "\tdisplay(f\"Model started training at {str(start)}\")\n",
    "\tfor chunk in train_slices:\n",
    "\t\tprint(f\"Chunk {chunk}\")\n",
    "\t\n",
    "\t\tclassifier.fit(train_features[chunk], train_labels[chunk])\n",
    "\t\tif save_quantum_model:\n",
    "\t\t\tclassifier.save(f\"./models/{base_model_name}-quantum.model\")\n",
    "\t\n",
    "\tfinish = datetime.now()\n",
    "\tprint(f\"Model trained at {str(finish)}, for a total time of {str(finish-start)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "114e49637b30088c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "if not skip_quantum:\n",
    "\ttesting_score = classifier.score(test_features, test_labels)\n",
    "\tprint(f\"Test dataset score:     {testing_score:.6f}\")\n",
    "\ttraining_score = classifier.score(train_features, train_labels)\n",
    "\tprint(f\"Training dataset score: {training_score:.6f}\")\n",
    "\tif sampler_choice == 2:\n",
    "\t\tsession.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97bdf5a9b5a9ffb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trained Local Effective Dimension and Display\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "\tquantum_local_ed_trained = LocalEffectiveDimension(qnn=sampler, weight_samples=classifier.weights, input_samples=train_features)\n",
    "\tquantum_local_ed_trained_measurement = np.array(quantum_local_ed_trained.get_effective_dimension(dataset_size=data_size_tests))/sampler.num_weights\n",
    "\tplt.plot(data_size_tests, quantum_local_ed_trained_measurement, label=\"Trained Weights\", color=(0.8,0.5,0.8))\n",
    "\tplt.plot(data_size_tests, quantum_local_ed_untrained_measurement, label=\"Untrained Weights\", color=(0.75,0.625,0.75))\n",
    "\tplt.xlabel(\"Number of data\")\n",
    "\tplt.ylabel(\"Normalized LOCAL effective dimension\")\n",
    "\tplt.legend()\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc9b88fc81a0459b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "\n",
    "if not skip_quantum and save_comparison_to_file:\n",
    "\twith open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "\t\tif sampler_choice == 1:\n",
    "\t\t\tfile.write(f\"Quantum Execution Location:\\tLocal Aer Simulator\\n\")\n",
    "\t\telif sampler_choice == 2:\n",
    "\t\t\tfile.write(f\"Quantum Execution Type:\\tRemote IBM {backend.name}\\n\")\n",
    "\t\telse:\n",
    "\t\t\tfile.write(f\"Quantum Execution Type:\\tLocal Default Simulator\\n\")\n",
    "\t\t\t\n",
    "\t\tfile.write(f\"Quantum Optimizer:\\t{type(quantum_optimizer).__name__}\\n\")\n",
    "\t\tfile.write(f\"Quantum Loss Function:\\t{type(quantum_loss).__name__}\\n\")\n",
    "\t\tfile.write(f\"Quantum Feature Map:\\t{type(feature_map).__name__}\\n\")\n",
    "\t\tfile.write(f\"Quantum Feature Map Number of Reps:\\t{feature_map.reps}\\n\")\n",
    "\t\tfile.write(f\"Quantum Ansatz:\\t{type(ansatz).__name__}\\n\")\n",
    "\t\tfile.write(f\"Quantum Ansatz Number of Reps:\\t{ansatz.reps}\\n\")\n",
    "\t\tfile.write(f\"Quantum Train Time:\\t{str(finish-start)}\\n\")\n",
    "\t\tfile.write(f\"Quantum Test Accuracy:\\t{testing_score}\\n\")\n",
    "\t\tfile.write(f\"Quantum Train Accuracy:\\t{training_score}\\n\")\n",
    "\t\tfile.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0312751e6f585bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dynamic Circuits Quantum Neural Network\n",
    "We construct a neural network that runs on IBM servers (due to memory limits)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e8a682c5f047f5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "\n",
    "# This factory creates a Dynamic Rotation Block quantum circuit of the desired size\n",
    "# It works by measuring a given quantum register to a classical bit then running\n",
    "# a conditional block based on that measurement.\n",
    "# Potential changes include making the conditional blocks input multiple classical bits\n",
    "# rather than just one.\n",
    "def DynamicFinalRotationBlockFactory(num_qubits:int) -> QuantumCircuit:\n",
    "\tq_reg = QuantumRegister(num_qubits)\n",
    "\tc_reg = ClassicalRegister(num_qubits)\n",
    "\n",
    "\trotation_block_circuit = QuantumCircuit(q_reg, c_reg)\n",
    "\tfor i in range(0, num_qubits, 1):\n",
    "\t\t\n",
    "\t\tparam0 = Parameter(name=f\"ле0[{i}]\") # ле0 (sha 0) represents the rotations if the qubit measure to 0.\n",
    "\t\tparam1 = Parameter(name=f\"ле1[{i}]\") # ле1 (sha 1) represents the rotations if the qubit measure to 1.\n",
    "\t\t\n",
    "\t\t# We measure the circuit as if at the end, seeing if we'd get a 1 or 0\n",
    "\t\trotation_block_circuit.measure(q_reg[i], c_reg[i])\n",
    "\t\t\n",
    "\t\t# The if test can see if it is a 1 or 0, and lets the model apply a final rotation\n",
    "\t\t# to change the results based on its output\n",
    "\t\twith rotation_block_circuit.if_test((c_reg[i], 0)) as else_:\n",
    "\t\t\t#rotation_block_circuit.h(i)\n",
    "\t\t\trotation_block_circuit.ry(param0,i)\n",
    "\t\twith else_:\n",
    "\t\t\t#rotation_block_circuit.h(i)\n",
    "\t\t\trotation_block_circuit.ry(param1,i)\n",
    "\t\t\n",
    "\t\t# We then finally measure the results, as otherwise the sampler cries\n",
    "\t\trotation_block_circuit.measure(q_reg[i], c_reg[i])\n",
    "\n",
    "\treturn rotation_block_circuit\n",
    "# Example of the structure of a dynamic rotation block.\n",
    "# It is meant to replace the final rotation block of the ansatz.\n",
    "DynamicFinalRotationBlockFactory(4).draw(output=\"mpl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2de305f7248bae2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Construct the circuit\n",
    "if not skip_dynamic:\n",
    "\t#feature_map = RawFeatureVector(num_features) # Note: RFV requires num_features = 2^k. Also known to break.\n",
    "\tdynamic_block = DynamicFinalRotationBlockFactory(dynamic_feature_map.num_qubits)\n",
    "\tdynamic_ansatz.compose(dynamic_block, inplace=True)\n",
    "\t\n",
    "\tdynamic_circuit = QuantumCircuit(dynamic_feature_map.num_qubits)\n",
    "\tdynamic_circuit.compose(dynamic_feature_map, inplace=True)\n",
    "\tdynamic_circuit.compose(dynamic_ansatz, inplace=True)\n",
    "\t\n",
    "\t#ansatz.decompose().draw(output=\"mpl\")\n",
    "\tdisplay(dynamic_circuit.draw(output=\"mpl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb774862eb152181"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the interpreting function for the model\n",
    "if skip_quantum and not skip_dynamic:\n",
    "\tdef interpret(x):\n",
    "\t\treturn x % num_targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb128791426a1566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configuring the Sampler primitive object\n",
    "if not skip_dynamic:\n",
    "\t\n",
    "\t#custom_sampler = qiskit.primitives.Sampler()\n",
    "\tdynamic_custom_sampler = qiskit_aer.primitives.Sampler()\n",
    "\t\n",
    "\tdynamic_sampler = SamplerQNN(sampler=dynamic_custom_sampler,\n",
    "\t\t\t\t\t\t circuit=dynamic_circuit,\n",
    "\t\t\t\t\t\t input_params=dynamic_feature_map.parameters,\n",
    "\t\t\t\t\t\t weight_params=dynamic_ansatz.parameters,\n",
    "\t\t\t\t\t\t interpret=interpret,\n",
    "\t\t\t\t\t\t output_shape=num_targets\n",
    "\t\t\t\t\t\t )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4880b2b911475f15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the graph callback function\n",
    "if not skip_dynamic:\n",
    "\tobjective_func_vals = []\n",
    "\tplt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\tplt.clf()\n",
    "\t\n",
    "if not skip_dynamic:\n",
    "\tdef dynamic_callback_graph(weights, obj_func_eval):\n",
    "\t\tclear_output(wait=True)\n",
    "\t\tobjective_func_vals.append(obj_func_eval)\n",
    "\t\tplt.title(\"Objective function value against iteration\")\n",
    "\t\tplt.xlabel(\"Iteration\")\n",
    "\t\tplt.ylabel(\"Objective function value\")\n",
    "\t\tplt.plot(range(len(objective_func_vals)), objective_func_vals, color=(0.5, 0.8, 0.8))\n",
    "\t\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e77ad2c572fe9cc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "if not skip_dynamic:\n",
    "\tif not reload_dynamic:\n",
    "\t\tdynamic_classifier = NeuralNetworkClassifier(\n",
    "\t\t\tdynamic_sampler,\n",
    "\t\t\tone_hot=True,\n",
    "\t\t\toptimizer=dynamic_quantum_optimizer,\n",
    "\t\t\tcallback=dynamic_callback_graph,\n",
    "\t\t\twarm_start=True,\n",
    "\t\t\tloss=dynamic_loss,\n",
    "\t\t\tinitial_point=algorithm_globals.random.random(dynamic_sampler.num_weights)\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\tdynamic_classifier = NeuralNetworkClassifier.load(f\"./models/{base_model_name}-dynamic.model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1007a76b5f77f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Global Effective Dimension Measure\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "\tdynamic_global_ed = EffectiveDimension(qnn=dynamic_sampler, weight_samples=num_eff_dim_weight_samples, input_samples=num_eff_dim_input_samples)\n",
    "\tdynamic_global_ed_measurement = np.array(dynamic_global_ed.get_effective_dimension(dataset_size=data_size_tests))/dynamic_sampler.num_weights\n",
    "\tplt.plot(data_size_tests, dynamic_global_ed_measurement, color=(0.5,0.8,0.8))\n",
    "\tplt.xlabel(\"Number of data\")\n",
    "\tplt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4625d31c74783b12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Untrained Local Effective Dimension\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "\tdynamic_local_ed_untrained = LocalEffectiveDimension(qnn=dynamic_sampler, weight_samples=dynamic_classifier.initial_point, input_samples=train_features)\n",
    "\tdynamic_local_ed_untrained_measurement = np.array(dynamic_local_ed_untrained.get_effective_dimension(dataset_size=data_size_tests))/dynamic_sampler.num_weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376af2c09265af93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "if not skip_dynamic:\n",
    "\tplt.clf()\n",
    "\tstart = datetime.now()\n",
    "\tdisplay(f\"Model started training at {str(start)}\")\n",
    "\tfor chunk in train_slices:\n",
    "\t\tprint(f\"Chunk {chunk}\")\n",
    "\n",
    "\t\tdynamic_classifier.fit(train_features[chunk], train_labels[chunk])\n",
    "\t\tif save_dynamic_model:\n",
    "\t\t\tdynamic_classifier.save(f\"./models/{base_model_name}-dynamic.model\")\n",
    "\t\n",
    "\tfinish = datetime.now()\n",
    "\tprint(f\"Model trained at {str(finish)}, for a total time of {str(finish - start)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae4785d9a2dd029"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trained Local Effective Dimension and Display\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "\tdynamic_local_ed_trained = LocalEffectiveDimension(qnn=dynamic_sampler, weight_samples=dynamic_classifier.weights, input_samples=train_features)\n",
    "\tdynamic_local_ed_trained_measurement = np.array(dynamic_local_ed_trained.get_effective_dimension(dataset_size=data_size_tests))/dynamic_sampler.num_weights\n",
    "\tplt.plot(data_size_tests, dynamic_local_ed_trained_measurement, label=\"Trained Weights\", color=(0.5,0.8,0.8))\n",
    "\tplt.plot(data_size_tests, dynamic_local_ed_untrained_measurement, label=\"Untrained Weights\", color=(0.625,0.75,0.75))\n",
    "\tplt.xlabel(\"Number of data\")\n",
    "\tplt.ylabel(\"Normalized LOCAL effective dimension\")\n",
    "\tplt.legend()\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57c8f9768e6c8d35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "if not skip_dynamic:\n",
    "\ttesting_score = dynamic_classifier.score(test_features, test_labels)  \n",
    "\tprint(f\"Test dataset score:     {testing_score:.6f}\")\n",
    "\ttraining_score = dynamic_classifier.score(train_features, train_labels)\n",
    "\tprint(f\"Training dataset score: {training_score:.6f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44a3c9c4e6c1f225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "if not skip_dynamic and save_comparison_to_file:\n",
    "\twith open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "\t\tfile.write(f\"Dynamic Execution Type:\\tLocal Aer Simulator\\n\")\n",
    "\t\tfile.write(f\"Dynamic Optimizer:\\t{type(dynamic_quantum_optimizer).__name__}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Loss Function:\\t{type(dynamic_loss).__name__}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Feature Map:\\t{type(dynamic_feature_map).__name__}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Feature Map Number of Reps:\\t{dynamic_feature_map.reps}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Ansatz:\\t{type(dynamic_ansatz).__name__} + {dynamic_desc}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Ansatz Number of Reps:\\t{dynamic_ansatz.reps}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Train Time:\\t{str(finish - start)}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Test Accuracy:\\t{testing_score}\\n\")\n",
    "\t\tfile.write(f\"Dynamic Train Accuracy:\\t{training_score}\\n\")\n",
    "\t\tfile.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e930fcebedf152"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import IPython.display\n",
    "\n",
    "if play_sound:\n",
    "\t# Beep to indicate finished job\n",
    "\tIPython.display.display(Audio(f\"./assets/{sound_filename}\", autoplay=True))\n",
    "display(f\"Finished at {datetime.now()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d413de53b93a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
