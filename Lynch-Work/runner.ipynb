{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This section is for workflow configuration.\n",
    "This includes:\n",
    "- Setting the name of this model\n",
    "- Choosing to skip certain parts\n",
    "- Choosing whether to reload a past model or not\n",
    "- Choosing which parts to save or not save\n",
    "- Choosing a seed for algorithms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1719b365348e4de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit.utils import algorithm_globals\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "base_model_name = \"covertype-ancilla-04\"  # Name to be used for saving and loading models. Filename friendly string\n",
    "# NOTE: Filename is not sanitized. Edit at your own risk.\n",
    "dataset_name = \"cover-type\"  # Name of the dataset. Used for the log file. String\n",
    "\n",
    "skip_effective_dimension = True  # If true, skip the effective dimension graphs for quantum and dynamic circuits\n",
    "# Can save time if you are simply interested in collecting accuracy data.\n",
    "\n",
    "skip_classical = True  # If true, skip the entire classical model parts.\n",
    "skip_quantum = True  # If true, skip the entire quantum model parts.\n",
    "skip_dynamic = False\n",
    "\n",
    "reload_classical = False  # If true, reload classical model from <base>-classical.keras.\n",
    "reload_quantum = False  # If true, reload quantum model from <base>-quantum.model.\n",
    "reload_dynamic = False\n",
    "\n",
    "save_classical_model = False  # If true, save classical model to <base>-classical.keras.\n",
    "save_quantum_model = False  # If true, save quantum model to <base>-quantum.model.\n",
    "save_dynamic_model = False\n",
    "\n",
    "save_comparison_to_file = True  # If true, save accuracy and runtime stats to <base>-comparison.log.\n",
    "overwrite_old_log = True  # If true and a log exists where this one would be saved, overwrite it\n",
    "skip_header = False  # When true, skip the header\n",
    "\n",
    "play_sound = True  # If true, play a sound when the notebook is finished.\n",
    "sound_filename = \"vine-boom.mp3\"  # Filename of sound to play. Must be located in ./assets\n",
    "# NOTE: Filename is not sanitized. Edit at your own risk.\n",
    "\n",
    "seed = random.randint(0, 99999)  # Seed for randomization. Integer\n",
    "algorithm_globals.random_seed = seed\n",
    "print(seed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2264a269b6ff50d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This section is for model configuration.\n",
    "This includes:\n",
    "- Number of iterations for training\n",
    "- Data sampling settings\n",
    "  - Whether to use a fraction or a set number for the data sample count.\n",
    "  - Fraction of data subset to sample.\n",
    "  - Number of data entries to sample \n",
    "- Fraction of data to use for training (rest is for testing)\n",
    "- Maximum size of data batches to be fed into the models.\n",
    "- Number of features for PCA reduction (used due to memory/qubit constraints.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d86064015dff6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iterations = 80  # The set iteration limit for the optimizer. Integer > 0\n",
    "use_frac = False  # If true, use data_frac as a fraction for sample size. Else use data_count.\n",
    "data_frac = 0.005  # Fraction of dataset to sample. Decimal [0-1]\n",
    "data_count = 250  # Number of data entries to sample. Integer [0-number of entries]\n",
    "train_frac = 0.8  # Fraction of data subset from above to use on training. Decimal [0-1]\n",
    "batch_size = 250  # Maximum batch size for models. Integer > 0\n",
    "num_features = 4  # Number of features for model. RFV requires a 2^k number. Integer [0-features]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61acf6c945ec99d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This section is for Classical Neural Network specific configuration\n",
    "This includes:\n",
    "- Which optimizer to use\n",
    "- Which loss function to use\n",
    "- How many neurons the classical neural network uses"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88d43e4557fba53f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classical_optimizer = \"adam\"\n",
    "classical_loss = \"mae\"\n",
    "classical_inner_neuron_count = num_features * 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfe7716aa2ac48a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This section is for Quantum Neural Network specific configuration\n",
    "This includes:\n",
    "- Which sampler primitive to use\n",
    "- Which optimizer to use\n",
    "- QNN optimization and resilience levels\n",
    "- QNN shots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c89f71c802dbe052"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import qiskit.algorithms.optimizers\n",
    "from qiskit.circuit.library import EfficientSU2, ZZFeatureMap, ZFeatureMap\n",
    "from qiskit_machine_learning.utils.loss_functions import L2Loss, L1Loss, CrossEntropyLoss\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "sampler_choice = 1  # Flag for which sampler to use. 0 = Default Sampler, 1 = Aer Sampler, 2 = IBM Sampler\n",
    "use_simulator = True  # If true, IBM Sampler will use a simulator. Otherwise, it will use a real machine.\n",
    "\n",
    "quantum_optimizer = qiskit.algorithms.optimizers.COBYLA(maxiter=iterations)\n",
    "# The optimizer object to use for optimizing the model.\n",
    "\n",
    "feature_map = ZFeatureMap(\n",
    "    num_features,\n",
    "    reps=1)\n",
    "ansatz = EfficientSU2(\n",
    "    num_qubits=feature_map.num_qubits,\n",
    "    reps=3,\n",
    "    flatten=True)\n",
    "quantum_loss = L2Loss()\n",
    "\n",
    "opt_level = 1  # The level of optimization for the circuits. [0, 1, 2, 3]\n",
    "res_level = 1  # The level of resilience hardening for the circuits. [0, 1, 2, 3]\n",
    "shots = 1024  # Number of repeated circuit executions for QNN. Integer > 0."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23eaff7fe9605aca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Effective Dimensions settings\n",
    "These settings are used for all effective dimension measurements, both in quantum and dynamic circuits."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5c088e34feafc79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_eff_dim_tests = 100  # Number of categories to use for ED data collection (think number of trials)\n",
    "num_eff_dim_data = 25000  # Maximum number of simulated data entries. The ED simulates incrementally larger 'datasets'\n",
    "num_eff_dim_weight_samples = 10  # Number of random weight arrays to choose from.\n",
    "num_eff_dim_input_samples = 10  # Number of random input arrays to choose from.\n",
    "ed_increment = int(num_eff_dim_data / num_eff_dim_tests)\n",
    "# The increment for the dataset sizes. \n",
    "# By default, it is the amount needed to fit num_eff_dim_tests data sizes.\n",
    "data_size_tests = [n for n in range(ed_increment, num_eff_dim_data + 1, ed_increment)]\n",
    "# An array of dataset sizes to be given to the effective dimension.\n",
    "# The values refer to how much data is simulated for the measurement."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a8cd23a1b0e7070"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This sections is for Dynamic QNN specific configuration\n",
    "This includes\n",
    "- Which optimizer to use\n",
    "- A description of the dynamic part of the algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2133b5ce74a27d11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dynamic_quantum_optimizer = qiskit.algorithms.optimizers.COBYLA(maxiter=iterations)\n",
    "dynamic_desc = \"Single Dynamic Rotation End Row with No Hadamards\"\n",
    "use_ancilla = False  # Determines if the dynamic circuit should utilize ancilla qubits for the dynamic rotation gates\n",
    "                    # instead of just using the existing qubits\n",
    "\n",
    "dynamic_feature_map = ZFeatureMap(\n",
    "    num_features,\n",
    "    reps=1)\n",
    "dynamic_ansatz_blank = EfficientSU2(\n",
    "    num_qubits=dynamic_feature_map.num_qubits,\n",
    "    reps=3,\n",
    "    skip_final_rotation_layer=True,\n",
    "    flatten=True)\n",
    "dynamic_loss = L2Loss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cc06acf76407e7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation\n",
    "Here we prepare the dataset we want for use in the models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a091deea6b3f18a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import fetch_covtype\n",
    "import pandas as pd\n",
    "from os.path import normpath\n",
    "\n",
    "# Put data samples into features and labels from file\n",
    "data = fetch_covtype(data_home=\"./data\", as_frame=True)\n",
    "display(data.target)\n",
    "num_targets = len(data.target.value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd937de05e04cf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_frac:\n",
    "    features = data.data.sample(frac=data_frac, random_state=seed)\n",
    "    labels = data.target.sample(frac=data_frac, random_state=seed).values\n",
    "else:\n",
    "    features = data.data.sample(n=data_count, random_state=seed)\n",
    "    labels = data.target.sample(n=data_count, random_state=seed).values\n",
    "features = features.values\n",
    "display(num_targets)\n",
    "display(features)\n",
    "display(labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77870e0313802aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Verify that the right number of features is present\n",
    "num_sample_targets = len(np.unique(labels))\n",
    "if num_sample_targets != num_targets: raise ValueError(f\"Number of targets in sample ({num_sample_targets}) does not match data's number of targets ({num_targets})!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "890d719d4d729122"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA the features, and preprocess them.\n",
    "features = PCA(n_components=num_features).fit_transform(features)\n",
    "features = StandardScaler().fit_transform(features)\n",
    "labels = OrdinalEncoder().fit_transform(labels.reshape(-1, 1))\n",
    "labels = labels[:, 0]\n",
    "display(features, labels)\n",
    "display(features.shape, labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267740847a4ac845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate into training and testing sets.\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    train_size=train_frac\n",
    ")\n",
    "display(train_features.shape, train_labels.shape, test_features.shape, test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcfb4f96b617cd21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Verify that the right number of features is present\n",
    "num_sample_targets = len(np.unique(train_labels))\n",
    "if num_sample_targets != num_targets: raise ValueError(f\"Number of targets in training sample ({num_sample_targets}) does not match data's number of targets ({num_targets})!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f730ce4d49a94f82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import gen_batches\n",
    "\n",
    "# Create the slices that we can use for batches in training\n",
    "train_slices = list(gen_batches(train_features.shape[0], batch_size))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cbf21cbe8db906"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Data logging\n",
    "if save_comparison_to_file and not skip_header:\n",
    "    if overwrite_old_log and os.path.isfile(f\"./logs/{base_model_name}.log\"):\n",
    "        os.remove(f\"./logs/{base_model_name}.log\")\n",
    "    with open(f\"./logs/{base_model_name}.log\", \"a+\") as file:\n",
    "        file.write(f\"Model Name:\\t{base_model_name}\\n\")\n",
    "        file.write(f\"Dataset:\\t{dataset_name}\\n\")\n",
    "        file.write(f\"Trial start:\\t{datetime.now()}\\n\")\n",
    "        file.write(f\"Number of features:\\t{num_features}\\n\")\n",
    "        file.write(f\"Number of data entries:\\t{features.shape[0]}\\n\")\n",
    "        file.write(f\"Batch size:\\t{batch_size}\\n\")\n",
    "        file.write(f\"Iterations:\\t{iterations}\\n\")\n",
    "        file.write(f\"Training fraction:\\t{train_frac}\\n\")\n",
    "        file.write(f\"Randomization seed:\\t{seed}\\n\")\n",
    "        file.write(\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f65a288ae7c0080"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classical Neural Network\n",
    "We now construct and run the classical neural network locally. This normally doesn't take long at all."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfad1280708c8cec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create the Keras neural network model\n",
    "if not skip_classical:\n",
    "    if not reload_classical:\n",
    "        classical_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(classical_inner_neuron_count,\n",
    "                                  activation=\"relu\",\n",
    "                                  input_shape=[num_features]),\n",
    "            tf.keras.layers.Dense(units=1)\n",
    "        ])\n",
    "    else:\n",
    "        classical_model = tf.keras.models.load_model(f\"./models/{base_model_name}-classical.keras\")\n",
    "    classical_model.compile(optimizer=classical_optimizer,\n",
    "                            loss=classical_loss,\n",
    "                            metrics=[\"accuracy\", \"sparse_categorical_accuracy\"]\n",
    "                            )\n",
    "    classical_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67bd49c78c14539d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile the model and use it\n",
    "if not skip_classical:\n",
    "    start = datetime.now()\n",
    "    classical_model.fit(x=train_features, y=train_labels, batch_size=batch_size, epochs=iterations)\n",
    "    finish = datetime.now()\n",
    "    print(f\"Model trained at {str(finish)}, for a total time of {str(finish - start)}\")\n",
    "    if save_classical_model:\n",
    "        classical_model.save(f\"./models/{base_model_name}-classical.keras\")\n",
    "    display(classical_model.metrics_names)\n",
    "    classical_test_result = classical_model.evaluate(x=test_features, y=test_labels)\n",
    "    classical_train_result = classical_model.evaluate(x=train_features, y=train_labels)\n",
    "    display(f\"Classical Training results: {classical_train_result}\")\n",
    "    display(f\"Classical Testing results: {classical_test_result}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c32b10abd93cc26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "\n",
    "if not skip_classical and save_comparison_to_file:\n",
    "    with open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "        file.write(f\"Classical Optimizer:\\t{classical_optimizer}\\n\")\n",
    "        file.write(f\"Classical Loss:\\t{classical_loss}\\n\")\n",
    "        file.write(f\"Classical Inner Neuron Count:\\t{classical_inner_neuron_count}\\n\")\n",
    "        file.write(f\"Classical Train Time:\\t{str(finish - start)}\\n\")\n",
    "        file.write(f\"Classical Testing Accuracy:\\t{classical_test_result[1]}\\n\")\n",
    "        file.write(f\"Classical Testing Sparse Categorical Accuracy:\\t{classical_test_result[2]}\\n\")\n",
    "        file.write(f\"Classical Training Accuracy:\\t{classical_train_result[1]}\\n\")\n",
    "        file.write(f\"Classical Training Sparse Categorical Accuracy:\\t{classical_train_result[2]}\\n\")\n",
    "        file.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2425b410d57d3c48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum Neural Network\n",
    "We construct a quantum neural network that can be ran locally or on an IBM simulator/quantum computer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39b29b45330154bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "\n",
    "# Construct the circuit\n",
    "if not skip_quantum:\n",
    "    #feature_map = RawFeatureVector(num_features) # Note: RFV requires num_features = 2^k. Also known to break.\n",
    "\n",
    "    circuit = QuantumCircuit(feature_map.num_qubits)\n",
    "    circuit.compose(feature_map, inplace=True)\n",
    "    circuit.compose(ansatz, inplace=True)\n",
    "\n",
    "    #ansatz.decompose().draw(output=\"mpl\")\n",
    "    display(circuit.draw(output=\"mpl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7df4eab2fb4ca6a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the interpreting function for the model\n",
    "if not skip_quantum:\n",
    "    def interpret(x):\n",
    "        return x % num_targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b566f5cb25d86d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Options\n",
    "import qiskit.primitives\n",
    "import qiskit_aer.primitives\n",
    "import qiskit_ibm_runtime.sampler\n",
    "from qiskit_ibm_runtime import Session\n",
    "\n",
    "# Configuring the Sampler primitive object\n",
    "if not skip_quantum:\n",
    "    if sampler_choice == 1:\n",
    "        custom_sampler = qiskit_aer.primitives.Sampler()\n",
    "        print(\"Aer sampler\")\n",
    "    elif sampler_choice == 2:\n",
    "        service = QiskitRuntimeService(\n",
    "            channel='ibm_quantum',\n",
    "            instance='ibm-q-asu/main/pi-deluca'\n",
    "        )\n",
    "\n",
    "        options = Options()\n",
    "        options.execution.shots = shots\n",
    "        options.optimization_level = opt_level\n",
    "        options.resilience_level = res_level\n",
    "        #options.transpilation.skip_transpilation = True\n",
    "\n",
    "        if use_simulator:\n",
    "            backend = service.get_backend(\"simulator_statevector\")\n",
    "        else:\n",
    "            backend = service.least_busy(min_num_qubits=feature_map.num_qubits,\n",
    "                                         filters=lambda b: (b.configuration().simulator == True) and (\n",
    "                                                     b.configuration().conditional == True))\n",
    "\n",
    "        print(backend.name)\n",
    "        session = Session(backend=backend, service=service)\n",
    "        custom_sampler = qiskit_ibm_runtime.Sampler(session=session, options=options)\n",
    "    else:\n",
    "        custom_sampler = qiskit.primitives.Sampler()\n",
    "        print(\"Default sampler\")\n",
    "\n",
    "    sampler = SamplerQNN(sampler=custom_sampler,\n",
    "                         circuit=circuit,\n",
    "                         input_params=feature_map.parameters,\n",
    "                         weight_params=ansatz.parameters,\n",
    "                         interpret=interpret,\n",
    "                         output_shape=num_targets\n",
    "                         )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34234c3727d54bbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define the graph callback function\n",
    "if not skip_quantum:\n",
    "    objective_func_vals = []\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    def callback_graph(weights, obj_func_eval):\n",
    "        clear_output(wait=True)\n",
    "        objective_func_vals.append(obj_func_eval)\n",
    "        plt.title(\"Objective function value against iteration\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Objective function value\")\n",
    "        plt.plot(range(len(objective_func_vals)), objective_func_vals, color=(0.8, 0.5, 0.8))\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d26b95f68f80e360"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
    "\n",
    "# Create classifier\n",
    "if not skip_quantum:\n",
    "    if not reload_quantum:\n",
    "        classifier = NeuralNetworkClassifier(\n",
    "            sampler,\n",
    "            one_hot=True,\n",
    "            optimizer=quantum_optimizer,\n",
    "            callback=callback_graph,\n",
    "            warm_start=True,\n",
    "            loss=quantum_loss,\n",
    "            initial_point=algorithm_globals.random.random(sampler.num_weights)\n",
    "        )\n",
    "    else:\n",
    "        classifier = NeuralNetworkClassifier.load(f\"./models/{base_model_name}-quantum.model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9b927d993945cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import EffectiveDimension\n",
    "\n",
    "# Global Effective Dimension Measure\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "    quantum_global_ed = EffectiveDimension(qnn=sampler, weight_samples=num_eff_dim_weight_samples,\n",
    "                                           input_samples=num_eff_dim_input_samples)\n",
    "    quantum_global_ed_measurement = np.array(\n",
    "        quantum_global_ed.get_effective_dimension(dataset_size=data_size_tests)) / sampler.num_weights\n",
    "    plt.plot(data_size_tests, quantum_global_ed_measurement, color=(0.8, 0.5, 0.8))\n",
    "    plt.xlabel(\"Number of data\")\n",
    "    plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a9e05e71e926abe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.neural_networks import LocalEffectiveDimension\n",
    "\n",
    "# Untrained Local Effective Dimension\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "    quantum_local_ed_untrained = LocalEffectiveDimension(qnn=sampler, weight_samples=classifier.initial_point,\n",
    "                                                         input_samples=train_features)\n",
    "    quantum_local_ed_untrained_measurement = np.array(\n",
    "        quantum_local_ed_untrained.get_effective_dimension(dataset_size=data_size_tests)) / sampler.num_weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315c38622209d73c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "if not skip_quantum:\n",
    "    plt.clf()\n",
    "    start = datetime.now()\n",
    "    display(f\"Model started training at {str(start)}\")\n",
    "    for chunk in train_slices:\n",
    "        print(f\"Chunk {chunk}\")\n",
    "\n",
    "        classifier.fit(train_features[chunk], train_labels[chunk])\n",
    "        if save_quantum_model:\n",
    "            classifier.save(f\"./models/{base_model_name}-quantum.model\")\n",
    "\n",
    "    finish = datetime.now()\n",
    "    print(f\"Model trained at {str(finish)}, for a total time of {str(finish - start)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "114e49637b30088c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "if not skip_quantum:\n",
    "    testing_score = classifier.score(test_features, test_labels)\n",
    "    print(f\"Test dataset score:     {testing_score:.6f}\")\n",
    "    training_score = classifier.score(train_features, train_labels)\n",
    "    print(f\"Training dataset score: {training_score:.6f}\")\n",
    "    if sampler_choice == 2:\n",
    "        session.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97bdf5a9b5a9ffb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trained Local Effective Dimension and Display\n",
    "if not skip_quantum and not skip_effective_dimension:\n",
    "    quantum_local_ed_trained = LocalEffectiveDimension(qnn=sampler, weight_samples=classifier.weights,\n",
    "                                                       input_samples=train_features)\n",
    "    quantum_local_ed_trained_measurement = np.array(\n",
    "        quantum_local_ed_trained.get_effective_dimension(dataset_size=data_size_tests)) / sampler.num_weights\n",
    "    plt.plot(data_size_tests, quantum_local_ed_trained_measurement, label=\"Trained Weights\", color=(0.8, 0.5, 0.8))\n",
    "    plt.plot(data_size_tests, quantum_local_ed_untrained_measurement, label=\"Untrained Weights\",\n",
    "             color=(0.75, 0.625, 0.75))\n",
    "    plt.xlabel(\"Number of data\")\n",
    "    plt.ylabel(\"Normalized LOCAL effective dimension\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc9b88fc81a0459b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "\n",
    "if not skip_quantum and save_comparison_to_file:\n",
    "    with open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "        if sampler_choice == 1:\n",
    "            file.write(f\"Quantum Execution Location:\\tLocal Aer Simulator\\n\")\n",
    "        elif sampler_choice == 2:\n",
    "            file.write(f\"Quantum Execution Type:\\tRemote IBM {backend.name}\\n\")\n",
    "        else:\n",
    "            file.write(f\"Quantum Execution Type:\\tLocal Default Simulator\\n\")\n",
    "\n",
    "        file.write(f\"Quantum Optimizer:\\t{type(quantum_optimizer).__name__}\\n\")\n",
    "        file.write(f\"Quantum Loss Function:\\t{type(quantum_loss).__name__}\\n\")\n",
    "        file.write(f\"Quantum Feature Map:\\t{type(feature_map).__name__}\\n\")\n",
    "        file.write(f\"Quantum Feature Map Number of Reps:\\t{feature_map.reps}\\n\")\n",
    "        file.write(f\"Quantum Ansatz:\\t{type(ansatz).__name__}\\n\")\n",
    "        file.write(f\"Quantum Ansatz Number of Reps:\\t{ansatz.reps}\\n\")\n",
    "        file.write(f\"Quantum Train Time:\\t{str(finish - start)}\\n\")\n",
    "        file.write(f\"Quantum Test Accuracy:\\t{testing_score}\\n\")\n",
    "        file.write(f\"Quantum Train Accuracy:\\t{training_score}\\n\")\n",
    "        file.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0312751e6f585bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dynamic Circuits Quantum Neural Network\n",
    "We construct a neural network that runs on IBM servers (due to memory limits)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e8a682c5f047f5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "from qiskit.circuit import Parameter, AncillaRegister\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "\n",
    "\n",
    "# This factory creates a Dynamic Rotation Block quantum circuit of the desired size\n",
    "# It works by measuring a given quantum register to a classical bit then running\n",
    "# a conditional block based on that measurement.\n",
    "# This does not accept an int, but rather an array of ints, the size of which should be the number of qubits for the circuit.\n",
    "# The ints within the array are used as a mask for the dynamic rotation blocks that are added to the circuit.\n",
    "# i.e., index 0 of the array determines what will be applied to qubit 0. The values are:\n",
    "#   A value > 1 results in the regular dynamic block being placed (both true and false block in an if_else).\n",
    "#   A value of 0 results in the false body being placed without any conditional components.\n",
    "#   A value of 1 results in the true body being placed without any conditional components.\n",
    "#   A value < 0 results in nothing being placed on that qubit.\n",
    "# add_ancilla is a bool that determines if the rotation block factory will add ancilla bits and entangle the existing\n",
    "# qubits to them or not. The ancilla qubits are used for getting a measurement of the state for the conditionals.\n",
    "# Ancillas are unnecessary for effective dimension measurements, and should be avoided.\n",
    "def DynamicFinalRotationBlockFactory(mask_array: List[int], add_ancilla: bool = False) -> QuantumCircuit:\n",
    "    q_reg = QuantumRegister(len(mask_array))\n",
    "    c_reg = ClassicalRegister(len(mask_array))\n",
    "    if add_ancilla:\n",
    "        ancilla_qregs = AncillaRegister(len(mask_array))\n",
    "        rotation_block_circuit = QuantumCircuit(q_reg, c_reg, ancilla_qregs)\n",
    "    else:\n",
    "        rotation_block_circuit = QuantumCircuit(q_reg, c_reg)\n",
    "    \n",
    "\n",
    "    for i in range(0, len(mask_array), 1):\n",
    "        param0 = Parameter(name=f\"Ш0[{i}]\")  # Ш0 (sha 0) represents the rotations if the qubit measure to 0.\n",
    "        param1 = Parameter(name=f\"Ш1[{i}]\")  # Ш1 (sha 1) represents the rotations if the qubit measure to 1.\n",
    "        # The true and false bodies can be replaced by any quantum circuit that uses 1 qubit. Just remember to \n",
    "        # adjust your parameters accordingly. Individual gates like RYGate also work.\n",
    "        true_body = QuantumCircuit(1)\n",
    "        true_body.ry(param1,0)\n",
    "        false_body = QuantumCircuit(1)\n",
    "        false_body.rz(param0,0)\n",
    "        \n",
    "        if add_ancilla and mask_array[i] > 1:\n",
    "            # First, we have to entangle the qubits to its ancilla if the option was selected,\n",
    "            rotation_block_circuit.h(ancilla_qregs[i])\n",
    "            rotation_block_circuit.cx(ancilla_qregs[i], q_reg[i])\n",
    "            qubits_to_modify = ancilla_qregs\n",
    "        else:\n",
    "            qubits_to_modify = q_reg\n",
    "        if mask_array[i] > 1:\n",
    "            # We measure the circuit as if at the end, seeing if we'd get a 1 or 0\n",
    "            rotation_block_circuit.measure(qubits_to_modify[i], c_reg[i])\n",
    "    \n",
    "            # The if-test can see if it is a 1 or 0, and lets the model apply a final rotation\n",
    "            # to change the results based on its output\n",
    "            with rotation_block_circuit.if_test((c_reg[i], 1)) as else_:\n",
    "                #rotation_block_circuit.h(i)\n",
    "                rotation_block_circuit.compose(other=true_body, qubits=[q_reg[i]], inplace=True)\n",
    "            with else_:\n",
    "                #rotation_block_circuit.h(i)\n",
    "                rotation_block_circuit.compose(other=false_body, qubits=[q_reg[i]], inplace=True)\n",
    "        elif mask_array[i] == 1:\n",
    "            rotation_block_circuit.compose(other=true_body, qubits=[q_reg[i]], inplace=True)\n",
    "        elif mask_array[i] == 0:\n",
    "            rotation_block_circuit.compose(other=false_body, qubits=[q_reg[i]], inplace=True)\n",
    "            \n",
    "\n",
    "        # We then finally measure the results, as otherwise the sampler cries\n",
    "        rotation_block_circuit.measure(q_reg[i], c_reg[i])\n",
    "\n",
    "    return rotation_block_circuit\n",
    "\n",
    "\n",
    "# Example of the structure of a dynamic rotation block.\n",
    "# It is meant to replace the final rotation block of the ansatz.\n",
    "DynamicFinalRotationBlockFactory([0,1,2,-1], add_ancilla=use_ancilla).draw(output=\"mpl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2de305f7248bae2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Construct the circuit\n",
    "if not skip_dynamic:\n",
    "    # We add the ancilla qubits if use_ancilla is True. This is needed for composing the rotation block with ancilla later on\n",
    "    if use_ancilla:\n",
    "        dynamic_circuit = QuantumCircuit(QuantumRegister(dynamic_feature_map.num_qubits), AncillaRegister(dynamic_feature_map.num_qubits))\n",
    "    else: \n",
    "        dynamic_circuit = QuantumCircuit(dynamic_feature_map.num_qubits)\n",
    "    \n",
    "    dynamic_circuit.compose(dynamic_feature_map, inplace=True)\n",
    "    \n",
    "    # Normal refers to the one that is trained. The others are for effective dimension measurements\n",
    "    dynamic_block_normal = DynamicFinalRotationBlockFactory([2 for x in range(0, dynamic_feature_map.num_qubits)], add_ancilla=use_ancilla)\n",
    "    # No need for ancilla on true and false, as there's no measurements done mid-circuit\n",
    "    dynamic_block_true = DynamicFinalRotationBlockFactory([1 for x in range(0, dynamic_feature_map.num_qubits)])\n",
    "    dynamic_block_false = DynamicFinalRotationBlockFactory([0 for x in range(0, dynamic_feature_map.num_qubits)])\n",
    "    \n",
    "    # We have to add the ancilla qubits to the ansatz for the composition to work\n",
    "    if use_ancilla:\n",
    "        dynamic_ansatz_blank_for_normal = QuantumCircuit(\n",
    "            QuantumRegister(dynamic_ansatz_blank.num_qubits),\n",
    "            AncillaRegister(dynamic_ansatz_blank.num_qubits)\n",
    "        )\n",
    "        dynamic_ansatz_blank_for_normal.compose(dynamic_ansatz_blank, inplace=True)\n",
    "    else:\n",
    "        dynamic_ansatz_blank_for_normal = dynamic_ansatz_blank\n",
    "    \n",
    "    dynamic_ansatz_normal = dynamic_ansatz_blank_for_normal.compose(dynamic_block_normal)\n",
    "    dynamic_ansatz_true = dynamic_ansatz_blank.compose(dynamic_block_true)\n",
    "    dynamic_ansatz_false = dynamic_ansatz_blank.compose(dynamic_block_false)\n",
    "\n",
    "    dynamic_circuit_blank = dynamic_circuit.compose(dynamic_ansatz_blank)\n",
    "    dynamic_circuit_normal = dynamic_circuit.compose(dynamic_ansatz_normal)\n",
    "    dynamic_circuit_true = dynamic_circuit.compose(dynamic_ansatz_true)\n",
    "    dynamic_circuit_false = dynamic_circuit.compose(dynamic_ansatz_false)\n",
    "\n",
    "    #ansatz.decompose().draw(output=\"mpl\")\n",
    "    display(dynamic_circuit_blank.draw(output=\"mpl\"))\n",
    "    display(dynamic_circuit_normal.draw(output=\"mpl\"))\n",
    "    display(dynamic_circuit_true.draw(output=\"mpl\"))\n",
    "    display(dynamic_circuit_false.draw(output=\"mpl\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb774862eb152181"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the interpreting function for the model\n",
    "if not skip_dynamic:\n",
    "    def dynamic_interpret(x):\n",
    "        return x % num_targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb128791426a1566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the graph callback function\n",
    "if not skip_dynamic:\n",
    "    objective_func_vals = []\n",
    "    plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "    plt.clf()\n",
    "\n",
    "if not skip_dynamic:\n",
    "    def dynamic_callback_graph(weights, obj_func_eval):\n",
    "        clear_output(wait=True)\n",
    "        objective_func_vals.append(obj_func_eval)\n",
    "        plt.title(\"Objective function value against iteration\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Objective function value\")\n",
    "        plt.plot(range(len(objective_func_vals)), objective_func_vals, color=(0.5, 0.8, 0.8))\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e77ad2c572fe9cc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configuring the Sampler primitive object\n",
    "if not skip_dynamic:\n",
    "\n",
    "    dynamic_custom_sampler = qiskit_aer.primitives.Sampler()\n",
    "\n",
    "    dynamic_sampler_blank = SamplerQNN(sampler=dynamic_custom_sampler,\n",
    "                                 circuit=dynamic_circuit_blank,\n",
    "                                 input_params=dynamic_feature_map.parameters,\n",
    "                                 weight_params=dynamic_ansatz_blank.parameters,\n",
    "                                 interpret=dynamic_interpret,\n",
    "                                 output_shape=num_targets\n",
    "                                 )\n",
    "    dynamic_sampler_normal = SamplerQNN(sampler=dynamic_custom_sampler,\n",
    "                                 circuit=dynamic_circuit_normal,\n",
    "                                 input_params=dynamic_feature_map.parameters,\n",
    "                                 weight_params=dynamic_ansatz_normal.parameters,\n",
    "                                 interpret=dynamic_interpret,\n",
    "                                 output_shape=num_targets\n",
    "                                 )\n",
    "    dynamic_sampler_true = SamplerQNN(sampler=dynamic_custom_sampler,\n",
    "                                 circuit=dynamic_circuit_true,\n",
    "                                 input_params=dynamic_feature_map.parameters,\n",
    "                                 weight_params=dynamic_ansatz_true.parameters,\n",
    "                                 interpret=dynamic_interpret,\n",
    "                                 output_shape=num_targets\n",
    "                                 )\n",
    "    dynamic_sampler_false = SamplerQNN(sampler=dynamic_custom_sampler,\n",
    "                                 circuit=dynamic_circuit_false,\n",
    "                                 input_params=dynamic_feature_map.parameters,\n",
    "                                 weight_params=dynamic_ansatz_false.parameters,\n",
    "                                 interpret=dynamic_interpret,\n",
    "                                 output_shape=num_targets\n",
    "                                 )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4880b2b911475f15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "if not skip_dynamic:\n",
    "    if not reload_dynamic:\n",
    "        # We get all the weights from the normal training by filtering the results. No need for extra classifiers.\n",
    "        dynamic_classifier = NeuralNetworkClassifier(\n",
    "            dynamic_sampler_normal,\n",
    "            one_hot=True,\n",
    "            optimizer=dynamic_quantum_optimizer,\n",
    "            callback=dynamic_callback_graph,\n",
    "            warm_start=True,\n",
    "            loss=dynamic_loss,\n",
    "            initial_point=algorithm_globals.random.random(dynamic_sampler_normal.num_weights)\n",
    "        )\n",
    "    else:\n",
    "        dynamic_classifier = NeuralNetworkClassifier.load(f\"./models/{base_model_name}-dynamic.model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c1007a76b5f77f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Global Effective Dimension Measure\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "    dynamic_global_ed_blank = EffectiveDimension(qnn=dynamic_sampler_blank, weight_samples=num_eff_dim_weight_samples,\n",
    "                                           input_samples=num_eff_dim_input_samples)\n",
    "    dynamic_global_ed_true = EffectiveDimension(qnn=dynamic_sampler_true, weight_samples=num_eff_dim_weight_samples,\n",
    "                                           input_samples=num_eff_dim_input_samples)\n",
    "    dynamic_global_ed_false = EffectiveDimension(qnn=dynamic_sampler_false, weight_samples=num_eff_dim_weight_samples,\n",
    "                                           input_samples=num_eff_dim_input_samples)\n",
    "    \n",
    "    \n",
    "    dynamic_global_ed_measurement_blank = np.array(\n",
    "        dynamic_global_ed_blank.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_blank.num_weights\n",
    "    dynamic_global_ed_measurement_true = np.array(\n",
    "        dynamic_global_ed_true.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_true.num_weights\n",
    "    dynamic_global_ed_measurement_false = np.array(\n",
    "        dynamic_global_ed_false.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_false.num_weights\n",
    "    \n",
    "    \n",
    "    plt.plot(data_size_tests, dynamic_global_ed_measurement_blank, label=\"All paths removed\")\n",
    "    plt.plot(data_size_tests, dynamic_global_ed_measurement_true, label=\"All true paths\")\n",
    "    plt.plot(data_size_tests, dynamic_global_ed_measurement_false, label=\"All false paths\")\n",
    "    plt.xlabel(\"Number of data\")\n",
    "    plt.ylabel(\"Normalized GLOBAL effective dimension\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4625d31c74783b12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Untrained Local Effective Dimension\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "   \n",
    "    param_to_initial_weight_dict = {str(param): weight for param, weight in zip(dynamic_sampler_normal.weight_params, dynamic_classifier.initial_point)}\n",
    "    \n",
    "    untrained_weights_blank = [param_to_initial_weight_dict[str(param)] for param in dynamic_sampler_blank.weight_params]\n",
    "    untrained_weights_true = [param_to_initial_weight_dict[str(param)] for param in dynamic_sampler_true.weight_params]\n",
    "    untrained_weights_false = [param_to_initial_weight_dict[str(param)] for param in dynamic_sampler_false.weight_params]\n",
    "    \n",
    "    dynamic_local_ed_untrained_blank = LocalEffectiveDimension(qnn=dynamic_sampler_blank,\n",
    "                                                         weight_samples=untrained_weights_blank,\n",
    "                                                         input_samples=train_features)\n",
    "    dynamic_local_ed_untrained_true = LocalEffectiveDimension(qnn=dynamic_sampler_true,\n",
    "                                                         weight_samples=untrained_weights_true,\n",
    "                                                         input_samples=train_features)\n",
    "    dynamic_local_ed_untrained_false = LocalEffectiveDimension(qnn=dynamic_sampler_false,\n",
    "                                                         weight_samples=untrained_weights_false,\n",
    "                                                         input_samples=train_features)\n",
    "    \n",
    "    dynamic_local_ed_untrained_measurement_blank = np.array(\n",
    "        dynamic_local_ed_untrained_blank.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_blank.num_weights\n",
    "    dynamic_local_ed_untrained_measurement_true = np.array(\n",
    "        dynamic_local_ed_untrained_true.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_true.num_weights\n",
    "    dynamic_local_ed_untrained_measurement_false = np.array(\n",
    "        dynamic_local_ed_untrained_false.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_false.num_weights\n",
    "    \n",
    "    plt.plot(data_size_tests, dynamic_local_ed_untrained_measurement_blank, label=\"All paths removed\")\n",
    "    plt.plot(data_size_tests, dynamic_local_ed_untrained_measurement_true, label=\"All true paths\")\n",
    "    plt.plot(data_size_tests, dynamic_local_ed_untrained_measurement_false, label=\"All false paths\")\n",
    "    plt.xlabel(\"Number of data\")\n",
    "    plt.ylabel(\"Normalized untrained LOCAL effective dimension\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376af2c09265af93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "if not skip_dynamic:\n",
    "    plt.clf()\n",
    "    start = datetime.now()\n",
    "    display(f\"Model started training at {str(start)}\")\n",
    "    for chunk in train_slices:\n",
    "        print(f\"Chunk {chunk}\")\n",
    "\n",
    "        dynamic_classifier.fit(train_features[chunk], train_labels[chunk])\n",
    "        if save_dynamic_model:\n",
    "            dynamic_classifier.save(f\"./models/{base_model_name}-dynamic.model\")\n",
    "\n",
    "    finish = datetime.now()\n",
    "    print(f\"Model trained at {str(finish)}, for a total time of {str(finish - start)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dae4785d9a2dd029"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trained Local Effective Dimension and Display\n",
    "if not skip_dynamic and not skip_effective_dimension:\n",
    "    param_to_weight_dict = {str(param): weight for param, weight in zip(dynamic_sampler_normal.weight_params, dynamic_classifier.weights)}\n",
    "    \n",
    "    trained_weights_blank = [param_to_weight_dict[str(param)] for param in dynamic_sampler_blank.weight_params]\n",
    "    trained_weights_true = [param_to_weight_dict[str(param)] for param in dynamic_sampler_true.weight_params]\n",
    "    trained_weights_false = [param_to_weight_dict[str(param)] for param in dynamic_sampler_false.weight_params]\n",
    "    \n",
    "    dynamic_local_ed_trained_blank = LocalEffectiveDimension(qnn=dynamic_sampler_blank,\n",
    "                                                         weight_samples=trained_weights_blank,\n",
    "                                                         input_samples=train_features)\n",
    "    dynamic_local_ed_trained_true = LocalEffectiveDimension(qnn=dynamic_sampler_true,\n",
    "                                                         weight_samples=trained_weights_true,\n",
    "                                                         input_samples=train_features)\n",
    "    dynamic_local_ed_trained_false = LocalEffectiveDimension(qnn=dynamic_sampler_false,\n",
    "                                                         weight_samples=trained_weights_false,\n",
    "                                                         input_samples=train_features)\n",
    "    \n",
    "    dynamic_local_ed_trained_measurement_blank = np.array(\n",
    "        dynamic_local_ed_trained_blank.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_blank.num_weights\n",
    "    dynamic_local_ed_trained_measurement_true = np.array(\n",
    "        dynamic_local_ed_trained_true.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_true.num_weights\n",
    "    dynamic_local_ed_trained_measurement_false = np.array(\n",
    "        dynamic_local_ed_trained_false.get_effective_dimension(dataset_size=data_size_tests)) / dynamic_sampler_false.num_weights\n",
    "    \n",
    "    plt.plot(data_size_tests, dynamic_local_ed_trained_measurement_blank, label=\"All paths removed\")\n",
    "    plt.plot(data_size_tests, dynamic_local_ed_trained_measurement_true, label=\"All true paths\")\n",
    "    plt.plot(data_size_tests, dynamic_local_ed_trained_measurement_false, label=\"All false paths\")\n",
    "    plt.xlabel(\"Number of data\")\n",
    "    plt.ylabel(\"Normalized trained LOCAL effective dimension\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57c8f9768e6c8d35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "if not skip_dynamic:\n",
    "    testing_score = dynamic_classifier.score(test_features, test_labels)\n",
    "    print(f\"Test dataset score:     {testing_score:.6f}\")\n",
    "    training_score = dynamic_classifier.score(train_features, train_labels)\n",
    "    print(f\"Training dataset score: {training_score:.6f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44a3c9c4e6c1f225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data logging\n",
    "if not skip_dynamic and save_comparison_to_file:\n",
    "    with open(f\"./logs/{base_model_name}.log\", \"a\") as file:\n",
    "        file.write(f\"Dynamic Execution Type:\\tLocal Aer Simulator\\n\")\n",
    "        file.write(f\"Dynamic Optimizer:\\t{type(dynamic_quantum_optimizer).__name__}\\n\")\n",
    "        file.write(f\"Dynamic Loss Function:\\t{type(dynamic_loss).__name__}\\n\")\n",
    "        file.write(f\"Dynamic Feature Map:\\t{type(dynamic_feature_map).__name__}\\n\")\n",
    "        file.write(f\"Dynamic Feature Map Number of Reps:\\t{dynamic_feature_map.reps}\\n\")\n",
    "        file.write(f\"Ancilla qubits used:\\t{use_ancilla}\\n\")\n",
    "        file.write(f\"Dynamic Ansatz:\\t{type(dynamic_ansatz_blank).__name__} + {dynamic_desc}\\n\")\n",
    "        file.write(f\"Dynamic Ansatz Number of Reps:\\t{dynamic_ansatz_blank.reps}\\n\")\n",
    "        file.write(f\"Dynamic Train Time:\\t{str(finish - start)}\\n\")\n",
    "        file.write(f\"Dynamic Test Accuracy:\\t{testing_score}\\n\")\n",
    "        file.write(f\"Dynamic Train Accuracy:\\t{training_score}\\n\")\n",
    "        file.write(f\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e930fcebedf152"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import IPython.display\n",
    "\n",
    "if play_sound:\n",
    "    # Beep to indicate finished job\n",
    "    IPython.display.display(Audio(f\"./assets/{sound_filename}\", autoplay=True))\n",
    "display(f\"Finished at {datetime.now()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d413de53b93a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4205eddd3d76d737"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
